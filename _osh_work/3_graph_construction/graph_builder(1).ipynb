{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"T6JcU0mIgshC","executionInfo":{"status":"ok","timestamp":1767165667447,"user_tz":-480,"elapsed":41,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"outputs":[],"source":["# Legal Reasoning Project, NCCU (2025)\n","# 1_graph_builder.ipynb: Build a knowledge graph for subsequent training work based on the structured osh document."]},{"cell_type":"code","source":["# revised by claude Sonnet\n","# manually upload osh_doc_merged.json"],"metadata":{"id":"a306zOIfpNue","executionInfo":{"status":"ok","timestamp":1767165667449,"user_tz":-480,"elapsed":9,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import json\n","import hashlib\n","import re\n","from typing import Dict, List, Tuple, Optional, Any, Set\n","import networkx as nx\n","from collections import defaultdict\n","import argparse\n","import os\n","from pathlib import Path"],"metadata":{"id":"234ujvW2hdbp","executionInfo":{"status":"ok","timestamp":1767165668378,"user_tz":-480,"elapsed":933,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Configuration: Ctrl + F the following keywords:\n","## \"input directory setting\"\n","## \"output directory setting\""],"metadata":{"id":"vxolV482OgJm","executionInfo":{"status":"ok","timestamp":1767165668397,"user_tz":-480,"elapsed":5,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ========================================\n","# 語義邊類型定義 (Semantic Edge Types)\n","# ========================================\n","\n","# === 歸責路徑 (Attribution Path) ===\n","EDGE_HAS_CAUSE = \"HAS_CAUSE\"              # Incident -> Cause\n","EDGE_ENABLED_BY = \"ENABLED_BY\"            # Cause -> Cause (Basic->Indirect->Direct)\n","EDGE_LEADS_TO = \"LEADS_TO\"                # Cause -> Violation (推理橋接)\n","EDGE_VIOLATES = \"VIOLATES_LAW\"            # Violation -> Regulation (法律對映)\n","\n","# === 關聯路徑 (Association Path) ===\n","EDGE_INVOLVES = \"INVOLVES_OBJECT\"         # Incident -> Medium\n","EDGE_IS_SUBCLASS = \"IS_SUBCLASS_OF\"       # Medium Hierarchy\n","EDGE_REGULATED_BY = \"REGULATED_BY\"        # Medium -> Regulation (需外部補充)\n","\n","# === 屬性與情境 ===\n","EDGE_OCCURS_IN = \"OCCURS_IN\"              # Incident -> Industry\n","EDGE_HAS_TYPE = \"HAS_INCIDENT_TYPE\"       # Incident -> IncidentType\n","EDGE_APPLIES_TO = \"APPLIES_TO_INCIDENT\"   # Regulation -> Incident (法規適用)"],"metadata":{"id":"qwbd7Zvthep1","executionInfo":{"status":"ok","timestamp":1767165668406,"user_tz":-480,"elapsed":2,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class OccupationalSafetyKnowledgeGraph:\n","    \"\"\"\n","    職業安全法律推論知識圖譜建構器 V2\n","\n","    設計目標:\n","    - 為大型語言模型 (LLM) 提供結構化的法律推理訓練數據\n","    - 支援圖神經網路 (GNN) 的異質圖學習\n","    - 保留完整的因果推理鏈與法律適用邏輯\n","    - 避免捷徑學習 (Shortcut Learning) 與數據污染\n","    \"\"\"\n","\n","    def __init__(self, strict_mode: bool = True, enable_semantic: bool = True):\n","        \"\"\"\n","        Args:\n","            strict_mode: 嚴格模式，啟用數據衛生檢查\n","            enable_semantic: 啟用語義相似度計算 (用於違規-原因匹配)\n","        \"\"\"\n","        self.graph = nx.MultiDiGraph()\n","        self.strict_mode = strict_mode\n","        self.enable_semantic = enable_semantic\n","\n","        # 統計資訊 (用於分析與除錯)\n","        self.stats = defaultdict(int)\n","        self.regulation_frequency = defaultdict(int)\n","        self.filtered_nodes = []  # 記錄被過濾的節點\n","\n","    def _generate_id(self, text: str, prefix: str = \"\") -> str:\n","        \"\"\"生成穩定且唯一的節點 ID\"\"\"\n","        if not text:\n","            return f\"{prefix}_UNKNOWN_{hash(text)}\"\n","        hash_val = hashlib.md5(text.encode('utf-8')).hexdigest()[:12]\n","        return f\"{prefix}_{hash_val}\"\n","\n","    def _clean_text(self, text: str) -> str:\n","        \"\"\"基礎文本清洗\"\"\"\n","        if not text:\n","            return \"\"\n","        # 移除多餘空白與換行\n","        text = re.sub(r'\\s+', ' ', text.strip())\n","        # 移除引號 (避免 JSON 問題)\n","        text = text.replace('\"', '').replace(\"'\", '')\n","        return text\n","\n","    def _is_valid_node(self, label: str, node_type: str = \"\") -> bool:\n","        \"\"\"\n","        [關鍵改動] 數據衛生檢查 (Data Sanitization)\n","\n","        過濾規則:\n","        1. 長度過短 (< 2 字元)\n","        2. LLM 拒絕回答的標記\n","        3. 無意義的通用詞\n","        4. 特定節點類型的額外檢查\n","        \"\"\"\n","        if not label or len(label.strip()) < 2:\n","            return False\n","\n","        label_lower = label.lower().strip()\n","\n","        # 通用無效關鍵字\n","        invalid_keywords = [\n","            \"抱歉\", \"無法提供\", \"無法提取\", \"沒有提供\",\n","            \"sorry\", \"none\", \"unknown\", \"n/a\", \"null\",\n","            \"無\", \"未知\", \"無資料\", \"無此資料\"\n","        ]\n","\n","        if any(kw in label_lower for kw in invalid_keywords):\n","            if self.strict_mode:\n","                self.filtered_nodes.append((label, node_type, \"invalid_keyword\"))\n","            return False\n","\n","        # 針對特定節點類型的檢查\n","        if node_type == \"Regulation\":\n","            # 法規必須包含法律名稱或條文號碼\n","            if not re.search(r'(法|條|規則|辦法|標準|第\\d+)', label):\n","                if self.strict_mode:\n","                    self.filtered_nodes.append((label, node_type, \"invalid_regulation\"))\n","                return False\n","\n","        if node_type == \"Cause\":\n","            # 原因不應該只是單一動詞或過於簡短\n","            if len(label.strip()) < 5:\n","                return False\n","\n","        return True\n","\n","    def _parse_cause_analysis(self, cause_text: str) -> Dict[str, str]:\n","        \"\"\"\n","        解析三層原因結構 (瑞士乳酪模型)\n","\n","        Returns:\n","            {\n","                'direct': '直接原因文本',\n","                'indirect': '間接原因文本',\n","                'basic': '基本原因文本'\n","            }\n","        \"\"\"\n","        causes = {'direct': '', 'indirect': '', 'basic': ''}\n","\n","        if not cause_text:\n","            return causes\n","\n","        # Pattern 1: 直接原因\n","        patterns = [\n","            r'[(\\(\\[]?一[)\\)\\]]?[、\\s]*直接原因[:\\s]+(.*?)(?=[(\\(\\[]?二[)\\)\\]]|$)',\n","            r'直接原因[:\\s]+(.*?)(?=間接原因|基本原因|$)'\n","        ]\n","        for pattern in patterns:\n","            match = re.search(pattern, cause_text, re.DOTALL)\n","            if match:\n","                causes['direct'] = self._clean_text(match.group(1))\n","                break\n","\n","        # Pattern 2: 間接原因\n","        patterns = [\n","            r'[(\\(\\[]?二[)\\)\\]]?[、\\s]*間接原因[:\\s]+(.*?)(?=[(\\(\\[]?三[)\\)\\]]|$)',\n","            r'間接原因[:\\s]+(.*?)(?=基本原因|$)'\n","        ]\n","        for pattern in patterns:\n","            match = re.search(pattern, cause_text, re.DOTALL)\n","            if match:\n","                causes['indirect'] = self._clean_text(match.group(1))\n","                break\n","\n","        # Pattern 3: 基本原因\n","        patterns = [\n","            r'[(\\(\\[]?三[)\\)\\]]?[、\\s]*基本原因[:\\s]+(.*?)$',\n","            r'基本原因[:\\s]+(.*?)$'\n","        ]\n","        for pattern in patterns:\n","            match = re.search(pattern, cause_text, re.DOTALL)\n","            if match:\n","                causes['basic'] = self._clean_text(match.group(1))\n","                break\n","\n","        return causes\n","\n","    def _extract_violations_from_summary(self, summary: str) -> List[str]:\n","        \"\"\"\n","        從 cause_summary 提取個別違規項目\n","\n","        Example:\n","            Input: \"「勞工未使用安全帶、雇主未設置安全衛生管理員」\"\n","            Output: [\"勞工未使用安全帶\", \"雇主未設置安全衛生管理員\"]\n","        \"\"\"\n","        if not summary:\n","            return []\n","\n","        # 移除引號\n","        clean = summary.strip('「」『』\"\"\\'\\'')\n","\n","        # 以頓號或逗號分割\n","        violations = re.split(r'[、,]', clean)\n","\n","        # 過濾與清洗\n","        result = []\n","        for v in violations:\n","            v = self._clean_text(v)\n","            if self._is_valid_node(v, \"Violation\"):\n","                result.append(v)\n","\n","        return result\n","\n","    def _parse_regulations(self, reg_text: str) -> List[Tuple[str, str]]:\n","        \"\"\"\n","        解析法規文字,返回 [(法規名稱, 條文號)] 列表\n","\n","        Example:\n","            Input: \"職業安全衛生設施規則第228條暨職業安全衛生法第6條第1項\"\n","            Output: [\n","                (\"職業安全衛生設施規則\", \"第228條\"),\n","                (\"職業安全衛生法\", \"第6條第1項\")\n","            ]\n","        \"\"\"\n","        if not reg_text:\n","            return []\n","\n","        regulations = []\n","\n","        # 先以逗號或頓號分割\n","        segments = re.split(r'[,、;]', reg_text)\n","\n","        for seg in segments:\n","            # 處理「暨」連接的多個法規\n","            sub_regs = re.split(r'暨', seg)\n","\n","            for sub in sub_regs:\n","                sub = self._clean_text(sub)\n","                if not sub:\n","                    continue\n","\n","                # 提取法規名稱與條文\n","                # Pattern: XXX法/規則/辦法/標準 + 第X條...\n","                pattern = r'(.*?(?:法|規則|辦法|標準))\\s*(第.*?)(?:$|[,、])'\n","                match = re.search(pattern, sub)\n","\n","                if match:\n","                    law_name = match.group(1).strip()\n","                    article = match.group(2).strip()\n","\n","                    # 驗證有效性\n","                    if self._is_valid_node(law_name, \"Regulation\"):\n","                        regulations.append((law_name, article))\n","                else:\n","                    # 無法精確解析,但如果看起來是法規,整段作為法規名稱\n","                    if re.search(r'(法|規則|辦法|標準)', sub):\n","                        if self._is_valid_node(sub, \"Regulation\"):\n","                            regulations.append((sub, \"\"))\n","\n","        return regulations\n","\n","    def _semantic_similarity(self, text1: str, text2: str) -> float:\n","        \"\"\"\n","        [修正版] 計算語義相似度\n","\n","        改進點:\n","        1. 使用 Bi-gram (雙字) 而非單字切分，提高中文匹配精確度。\n","           (例如: 避免 \"安全帽\" 與 \"安全帶\" 被誤判為高度相似)\n","        2. 加入長度懲罰，避免短字串導致的分數虛高。\n","        \"\"\"\n","        if not text1 or not text2:\n","            return 0.0\n","\n","        # 預處理：移除常見停用詞與標點\n","        stop_chars = \"的，、。；：未無有\"\n","        t1 = \"\".join([c for c in text1 if c not in stop_chars])\n","        t2 = \"\".join([c for c in text2 if c not in stop_chars])\n","\n","        if not t1 or not t2:\n","            return 0.0\n","\n","        # 使用 Bi-gram (雙字) 集合\n","        # \"高空作業\" -> {\"高空\", \"空作\", \"作業\"}\n","        s1 = set(t1[i:i+2] for i in range(len(t1)-1))\n","        s2 = set(t2[i:i+2] for i in range(len(t2)-1))\n","\n","        # 如果字串太短無法形成 bigram，退回單字比對\n","        if not s1: s1 = set(t1)\n","        if not s2: s2 = set(t2)\n","\n","        intersection = len(s1 & s2)\n","        union = len(s1 | s2)\n","\n","        score = intersection / union if union > 0 else 0.0\n","\n","        # TODO (Future Work): 在這裡接入 sentence-transformers\n","        # from sentence_transformers import util\n","        # score = util.pytorch_cos_sim(self.model.encode(text1), self.model.encode(text2))\n","\n","        return score\n","\n","    # ========================================\n","    # 圖構建主流程\n","    # ========================================\n","\n","    def build_graph(self, incidents_data: List[Dict[str, Any]]) -> nx.MultiDiGraph:\n","        \"\"\"\n","        主構建流程\n","\n","        Args:\n","            incidents_data: 事故資料列表\n","\n","        Returns:\n","            構建完成的知識圖譜\n","        \"\"\"\n","        print(f\"開始構建知識圖譜，共 {len(incidents_data)} 筆事件...\")\n","        print(f\"嚴格模式: {self.strict_mode}, 語義分析: {self.enable_semantic}\")\n","\n","        for idx, incident in enumerate(incidents_data, 1):\n","            try:\n","                self._process_single_incident(incident)\n","\n","                if idx % 10 == 0:\n","                    print(f\"已處理 {idx}/{len(incidents_data)} 筆資料\")\n","\n","            except Exception as e:\n","                print(f\"⚠ 處理第 {idx} 筆資料時發生錯誤: {str(e)}\")\n","                continue\n","\n","        # 輸出統計\n","        print(f\"\\n{'='*60}\")\n","        print(f\"圖譜構建完成:\")\n","        print(f\"  節點數: {self.graph.number_of_nodes()}\")\n","        print(f\"  邊數: {self.graph.number_of_edges()}\")\n","\n","        if self.strict_mode and self.filtered_nodes:\n","            print(f\"  過濾節點數: {len(self.filtered_nodes)}\")\n","            print(f\"  (詳見 get_filtered_nodes() 方法)\")\n","\n","        print(f\"{'='*60}\\n\")\n","\n","        return self.graph\n","\n","    def _process_single_incident(self, data: Dict):\n","        \"\"\"處理單一事件，構建完整的雙路徑結構\"\"\"\n","\n","        # 1. 建立核心事件節點 (Anchor Node)\n","        inc_text = data.get('description_summary', '') or data.get('description', '')\n","        if not self._is_valid_node(inc_text, \"Incident\"):\n","            return\n","\n","        inc_id = self._generate_id(inc_text, \"INC\")\n","\n","        self.graph.add_node(\n","            inc_id,\n","            node_type=\"Incident\",\n","            label=inc_text[:100] + \"...\" if len(inc_text) > 100 else inc_text,\n","            full_text=inc_text,\n","            industry=data.get('industry', 'Unknown'),\n","            incident_type=data.get('incident_type', 'Unknown'),\n","            incident_type_id=data.get('incident_type_id', '')\n","        )\n","\n","        self.stats['incident'] += 1\n","\n","        # 2. 建構「歸責路徑」 (Attribution Path)\n","        # Incident -> Cause Chain -> Violation -> Regulation\n","        cause_ids = self._build_causal_chain(inc_id, data)\n","        self._build_attribution_path(inc_id, cause_ids, data)\n","\n","        # 3. 建構「關聯路徑」 (Association Path)\n","        # Incident -> Medium Hierarchy\n","        self._build_association_path(inc_id, data)\n","\n","        # 4. 建構情境屬性\n","        self._build_contextual_attributes(inc_id, data)\n","\n","    def _build_causal_chain(self, inc_id: str, data: Dict) -> Dict[str, str]:\n","        \"\"\"\n","        [修正版] 建立三層因果鏈 (Swiss Cheese Model)\n","\n","        改進點:\n","        1. 加入 Fallback 機制: 如果 Regex 解析失敗，嘗試使用整個欄位內容。\n","        2. 加入 Description Injection: 如果完全沒有原因欄位，從事故描述中生成推論原因。\n","        3. 確保回傳的 cause_ids 至少有一個節點，避免圖譜斷鏈。\n","        \"\"\"\n","        raw_cause_text = data.get('cause_analysis', '')\n","        causes = self._parse_cause_analysis(raw_cause_text)\n","\n","        # === Fallback 策略 1: 寬鬆提取 ===\n","        # 如果正規表達式沒抓到東西，但欄位裡其實有字，就將整段文字視為「直接原因」\n","        if not any(causes.values()) and raw_cause_text:\n","            cleaned = self._clean_text(raw_cause_text)\n","            if self._is_valid_node(cleaned, \"Cause\"):\n","                causes['direct'] = cleaned\n","\n","        # === Fallback 策略 2: 從描述推論 (Description Injection) ===\n","        # 如果完全沒有原因資料，為了維持圖連通性，從 Summary 或 Description 提取\n","        if not any(causes.values()):\n","            # 優先使用摘要，若無則使用描述的前段\n","            source_text = data.get('description_summary') or data.get('description', '')\n","            source_text = self._clean_text(source_text)\n","\n","            if source_text:\n","                # 簡單啟發式：通常原因會接在「因...」或「由於...」之後 (這裡簡化處理)\n","                # 這裡建立一個特殊節點，標記為 Inferred (推論而得)\n","                causes['direct'] = source_text[:100]  # 截取前100字作為原因概括\n","\n","        cause_ids = {}\n","\n","        # 定義因果鏈層級\n","        # 注意：這裡允許 Inferred 類型的出現\n","        chain = [\n","            ('basic', causes['basic'], 'Cause_Basic'),\n","            ('indirect', causes['indirect'], 'Cause_Indirect'),\n","            ('direct', causes['direct'], 'Cause_Direct')\n","        ]\n","\n","        prev_id = None\n","\n","        for level, cause_text, node_type in chain:\n","            if not cause_text:\n","                continue\n","\n","            # 注意：對於 Fallback 產生的原因，我們可能需要放寬一點 valid check\n","            if not self._is_valid_node(cause_text, \"Cause\"):\n","                continue\n","\n","            cause_id = self._generate_id(cause_text, f\"CAUSE_{level.upper()}\")\n","            cause_ids[level] = cause_id\n","\n","            # 添加原因節點\n","            self.graph.add_node(\n","                cause_id,\n","                node_type=node_type,\n","                label=cause_text,\n","                cause_level=level,\n","                text_length=len(cause_text),\n","                is_inferred=(not raw_cause_text) # 標記是否為推論資料\n","            )\n","\n","            self.stats[f'cause_{level}'] += 1\n","\n","            # 建立層級間的因果關係 Basic -> Indirect -> Direct\n","            if prev_id:\n","                self.graph.add_edge(\n","                    prev_id, cause_id,\n","                    relation=EDGE_ENABLED_BY,\n","                    weight=1.0,\n","                    causal_strength='strong'\n","                )\n","\n","            prev_id = cause_id\n","\n","        # 連接到事故 (最後一個原因 -> Incident)\n","        if prev_id:\n","            self.graph.add_edge(\n","                prev_id, inc_id,\n","                relation=EDGE_HAS_CAUSE,\n","                weight=1.0,\n","                causal_strength='direct'\n","            )\n","        else:\n","            # === Ultimate Fallback: 防止孤立節點 ===\n","            # 如果經過上述努力還是沒有原因節點，創建一個 Unknown Cause\n","            unk_id = f\"CAUSE_UNKNOWN_{inc_id}\"\n","            self.graph.add_node(unk_id, node_type=\"Cause_Unknown\", label=\"未知原因\")\n","            self.graph.add_edge(unk_id, inc_id, relation=EDGE_HAS_CAUSE, weight=0.1)\n","            cause_ids['unknown'] = unk_id\n","\n","        return cause_ids\n","\n","    def _build_attribution_path(self, inc_id: str, cause_ids: Dict[str, str], data: Dict):\n","        \"\"\"\n","        [修正版] 構建歸責路徑: Cause -> Violation -> Regulation\n","\n","        改進點:\n","        1. 解決 Semantic Broadcasting: 只有當原因與法規/違規語義相關時才連結。\n","        2. 嚴格的相似度閾值: 防止「未戴安全帽」連結到「鷹架法規」。\n","        3. 動態權重: 根據相似度給予邊不同的權重 (Weight)。\n","        \"\"\"\n","\n","        regulations = self._parse_regulations(data.get('preventive_regulations', ''))\n","        violations_text = self._extract_violations_from_summary(data.get('cause_summary', ''))\n","\n","        # 收集所有有效的原因節點 ID 與其文本\n","        valid_causes = [] # list of (id, text, type)\n","        for level, cid in cause_ids.items():\n","            if cid in self.graph:\n","                valid_causes.append((cid, self.graph.nodes[cid]['label'], level))\n","\n","        # 設定語義匹配閾值 (可調整)\n","        SIMILARITY_THRESHOLD = 0.15  # Bi-gram 下，0.15 通常代表有共用關鍵詞\n","\n","        # === Path A: 透過明確的 Violation 節點橋接 (Cause -> Violation -> Regulation) ===\n","        if violations_text:\n","            for vio_text in violations_text:\n","                vio_id = self._generate_id(vio_text, \"VIO\")\n","\n","                # 建立 Violation 節點\n","                actor = 'employer' if '雇主' in vio_text else 'worker' if '勞工' in vio_text else 'unknown'\n","                self.graph.add_node(\n","                    vio_id, node_type=\"Violation\", label=vio_text,\n","                    actor=actor, is_omission='未' in vio_text\n","                )\n","                self.stats['violation'] += 1\n","\n","                # 1. Link Cause -> Violation (with Filtering)\n","                linked_cause = False\n","                for cid, c_text, c_level in valid_causes:\n","                    sim = self._semantic_similarity(vio_text, c_text)\n","\n","                    # 只有相似度夠高，或是文字包含關係，才建立連結\n","                    if sim > SIMILARITY_THRESHOLD or vio_text in c_text or c_text in vio_text:\n","                        self.graph.add_edge(\n","                            cid, vio_id,\n","                            relation=EDGE_LEADS_TO,\n","                            weight=max(0.5, sim),\n","                            sim_score=sim\n","                        )\n","                        linked_cause = True\n","\n","                # 如果沒有任何原因匹配到這個違規 (可能是推論不足)，強制連結最後一層原因 (Direct)\n","                if not linked_cause and valid_causes:\n","                    # 取最後一個原因 (通常是 Direct)\n","                    last_cid = valid_causes[-1][0]\n","                    self.graph.add_edge(last_cid, vio_id, relation=EDGE_LEADS_TO, weight=0.3, note=\"forced_link\")\n","\n","                # 2. Link Violation -> Regulation (with Filtering)\n","                for law_name, article in regulations:\n","                    reg_text = f\"{law_name} {article}\".strip()\n","                    reg_id = self._generate_id(reg_text, \"REG\")\n","\n","                    if reg_id not in self.graph:\n","                        self.graph.add_node(reg_id, node_type=\"Regulation\", label=reg_text, law_name=law_name)\n","                        self.stats['regulation'] += 1\n","                    self.regulation_frequency[reg_id] += 1\n","\n","                    # 計算違規行為與法規的相似度\n","                    # 注意：法規文字通常很長，這裡主要比對法規名稱或內容摘要(如有)\n","                    # 這裡假設 label 包含法規名稱，這對於匹配幫助有限，理想是需要法規全文\n","                    # 但為了防止完全無關的廣播，我們至少檢查法規名稱中的關鍵字是否出現在違規中\n","                    # (例如: 違規有\"墜落\"，法規是\"高空作業...\")\n","\n","                    # 暫時策略：全連結，但在邊上標記這是從哪個 Violation 來的，\n","                    # 真正的過濾應該發生在 Cause -> Violation 階段\n","                    self.graph.add_edge(\n","                        vio_id, reg_id,\n","                        relation=EDGE_VIOLATES,\n","                        weight=1.0\n","                    )\n","\n","        # === Path B: 隱含路徑 (Cause -> Implicit Violation -> Regulation) ===\n","        # 當沒有明確的 cause_summary 時使用\n","        else:\n","            for law_name, article in regulations:\n","                reg_text = f\"{law_name} {article}\".strip()\n","                reg_id = self._generate_id(reg_text, \"REG\")\n","\n","                if reg_id not in self.graph:\n","                    self.graph.add_node(reg_id, node_type=\"Regulation\", label=reg_text, law_name=law_name)\n","                    self.stats['regulation'] += 1\n","                self.regulation_frequency[reg_id] += 1\n","\n","                if valid_causes:\n","                    for cid, c_text, c_level in valid_causes:\n","                        # 這裡進行關鍵過濾：原因是否跟這條法規有關？\n","                        # 如果完全沒關係，就不連，避免 broadcasting\n","                        sim = self._semantic_similarity(c_text, reg_text)\n","\n","                        if sim > SIMILARITY_THRESHOLD * 0.8: # 法規文字較短，降低一點閾值\n","                            # 建立隱含違規節點作為橋梁\n","                            vio_id = self._generate_id(f\"IMP_{cid}_{reg_id}\", \"VIO\")\n","                            if vio_id not in self.graph:\n","                                self.graph.add_node(\n","                                    vio_id, node_type=\"Violation\",\n","                                    label=\"推論違規\", is_implicit=True\n","                                )\n","\n","                            self.graph.add_edge(cid, vio_id, relation=EDGE_LEADS_TO, weight=sim)\n","                            self.graph.add_edge(vio_id, reg_id, relation=EDGE_VIOLATES, weight=sim)\n","                else:\n","                    # 無原因，直接 Incident -> Regulation\n","                    self.graph.add_edge(inc_id, reg_id, relation=\"DIRECT_LIABILITY\", weight=0.5)\n","\n","    def _build_association_path(self, inc_id: str, data: Dict):\n","        \"\"\"\n","        構建關聯路徑: Incident -> Medium Hierarchy\n","\n","        三層分類樹: Specific -> Normal -> General\n","        \"\"\"\n","        levels = [\n","            ('specific', data.get('medium_type_specific', ''),\n","             data.get('medium_type_specific_id', '')),\n","            ('normal', data.get('medium_type_normal', ''),\n","             data.get('medium_type_normal_id', '')),\n","            ('general', data.get('medium_type_general', ''),\n","             data.get('medium_type_general_id', ''))\n","        ]\n","\n","        prev_id = inc_id\n","\n","        for level, label, code in levels:\n","            if not label or not code:\n","                continue\n","\n","            if not self._is_valid_node(label, \"Medium\"):\n","                continue\n","\n","            node_id = self._generate_id(f\"{label}_{code}\", f\"MED_{level.upper()}\")\n","\n","            # 添加節點 (如果已存在則跳過)\n","            if node_id not in self.graph:\n","                self.graph.add_node(\n","                    node_id,\n","                    node_type=f\"Medium_{level.capitalize()}\",\n","                    label=label,\n","                    code=code,\n","                    category_level=level\n","                )\n","                self.stats[f'medium_{level}'] += 1\n","\n","            # 建立層級關係\n","            if prev_id == inc_id:\n","                # Incident -> Medium_Specific\n","                self.graph.add_edge(\n","                    inc_id, node_id,\n","                    relation=EDGE_INVOLVES,\n","                    weight=1.0\n","                )\n","            else:\n","                # Medium_Specific -> Medium_Normal -> Medium_General\n","                self.graph.add_edge(\n","                    node_id, prev_id,  # 注意方向: 子類 -> 父類\n","                    relation=EDGE_IS_SUBCLASS,\n","                    weight=0.8\n","                )\n","\n","            prev_id = node_id\n","\n","    def _build_contextual_attributes(self, inc_id: str, data: Dict):\n","        \"\"\"\n","        建構情境屬性: 產業、事故類型等\n","\n","        這些屬性用於訓練情境理解能力\n","        \"\"\"\n","        # 產業\n","        industry = data.get('industry', '')\n","        if industry and self._is_valid_node(industry, \"Industry\"):\n","            ind_id = self._generate_id(industry, \"IND\")\n","\n","            if ind_id not in self.graph:\n","                self.graph.add_node(\n","                    ind_id,\n","                    node_type=\"Industry\",\n","                    label=industry\n","                )\n","                self.stats['industry'] += 1\n","\n","            self.graph.add_edge(\n","                inc_id, ind_id,\n","                relation=EDGE_OCCURS_IN,\n","                weight=0.5\n","            )\n","\n","        # 事故類型\n","        inc_type = data.get('incident_type', '')\n","        inc_type_id = data.get('incident_type_id', '')\n","\n","        if inc_type and inc_type_id:\n","            type_id = self._generate_id(f\"{inc_type}_{inc_type_id}\", \"TYPE\")\n","\n","            if type_id not in self.graph:\n","                self.graph.add_node(\n","                    type_id,\n","                    node_type=\"IncidentType\",\n","                    label=inc_type,\n","                    code=inc_type_id\n","                )\n","                self.stats['incident_type'] += 1\n","\n","            self.graph.add_edge(\n","                inc_id, type_id,\n","                relation=EDGE_HAS_TYPE,\n","                weight=0.5\n","            )\n","\n","    # ========================================\n","    # 分析與輸出方法\n","    # ========================================\n","\n","    def get_statistics(self) -> Dict:\n","        \"\"\"返回圖譜統計資訊\"\"\"\n","        node_types = defaultdict(int)\n","        edge_relations = defaultdict(int)\n","\n","        for node, data in self.graph.nodes(data=True):\n","            node_types[data.get('node_type', 'Unknown')] += 1\n","\n","        for u, v, data in self.graph.edges(data=True):\n","            edge_relations[data.get('relation', 'Unknown')] += 1\n","\n","        return {\n","            'total_nodes': self.graph.number_of_nodes(),\n","            'total_edges': self.graph.number_of_edges(),\n","            'node_type_distribution': dict(node_types),\n","            'edge_relation_distribution': dict(edge_relations),\n","            'most_cited_regulations': sorted(\n","                self.regulation_frequency.items(),\n","                key=lambda x: x[1],\n","                reverse=True\n","            )[:20],\n","            'graph_density': nx.density(self.graph),\n","            'is_connected': nx.is_weakly_connected(self.graph),\n","            'construction_stats': dict(self.stats)\n","        }\n","\n","    def get_filtered_nodes(self) -> List[Tuple[str, str, str]]:\n","        \"\"\"返回被過濾的節點列表 (用於除錯)\"\"\"\n","        return self.filtered_nodes\n","\n","    def export_readable_summary(self, filepath: str):\n","        \"\"\"輸出人類可讀的圖譜摘要報告\"\"\"\n","        with open(filepath, 'w', encoding='utf-8') as f:\n","            f.write(\"=\" * 80 + \"\\n\")\n","            f.write(\"台灣職業安全法律知識圖譜 - V2 建構品質報告\\n\")\n","            f.write(\"=\" * 80 + \"\\n\\n\")\n","\n","            stats = self.get_statistics()\n","\n","            # 1. 總體統計\n","            f.write(\"【一】總體統計\\n\")\n","            f.write(f\"總節點數: {stats['total_nodes']}\\n\")\n","            f.write(f\"總邊數: {stats['total_edges']}\\n\")\n","            f.write(f\"圖密度: {stats['graph_density']:.6f}\\n\")\n","            f.write(f\"是否連通: {'是' if stats['is_connected'] else '否'}\\n\\n\")\n","\n","            # 2. 節點類型分布\n","            f.write(\"【二】節點類型分布\\n\")\n","            for ntype, count in sorted(stats['node_type_distribution'].items(),\n","                                      key=lambda x: x[1], reverse=True):\n","                f.write(f\"  {ntype:30s}: {count:5d} 個\\n\")\n","            f.write(\"\\n\")\n","\n","            # 3. 邊關係類型分布\n","            f.write(\"【三】邊關係類型分布（關鍵設計指標）\\n\")\n","            f.write(\"  [歸責路徑]\\n\")\n","            attribution_edges = [EDGE_HAS_CAUSE, EDGE_ENABLED_BY, EDGE_LEADS_TO, EDGE_VIOLATES]\n","            for rel in attribution_edges:\n","                count = stats['edge_relation_distribution'].get(rel, 0)\n","                f.write(f\"    {rel:30s}: {count:5d} 條\\n\")\n","\n","            f.write(\"  [關聯路徑]\\n\")\n","            association_edges = [EDGE_INVOLVES, EDGE_IS_SUBCLASS, EDGE_REGULATED_BY]\n","            for rel in association_edges:\n","                count = stats['edge_relation_distribution'].get(rel, 0)\n","                f.write(f\"    {rel:30s}: {count:5d} 條\\n\")\n","\n","            f.write(\"  [其他關係]\\n\")\n","            other_rels = set(stats['edge_relation_distribution'].keys()) - \\\n","                        set(attribution_edges) - set(association_edges)\n","            for rel in sorted(other_rels):\n","                count = stats['edge_relation_distribution'][rel]\n","                f.write(f\"    {rel:30s}: {count:5d} 條\\n\")\n","            f.write(\"\\n\")\n","\n","            # 4. 最常被引用的法規 (TOP 20)\n","            f.write(\"【四】最常被引用的法規 (TOP 20)\\n\")\n","            for idx, (reg_id, freq) in enumerate(stats['most_cited_regulations'], 1):\n","                if reg_id in self.graph:\n","                    reg_label = self.graph.nodes[reg_id].get('label', reg_id)\n","                    f.write(f\"  {idx:2d}. {reg_label:60s} (引用 {freq:3d} 次)\\n\")\n","            f.write(\"\\n\")\n","\n","            # 5. 資料品質指標\n","            f.write(\"【五】資料品質指標\\n\")\n","            f.write(f\"  成功建構事件: {stats['construction_stats'].get('incident', 0)} 個\\n\")\n","            f.write(f\"  有效原因節點: {sum(stats['construction_stats'].get(f'cause_{l}', 0) for l in ['basic', 'indirect', 'direct'])} 個\\n\")\n","            f.write(f\"  違規節點: {stats['construction_stats'].get('violation', 0)} 個\\n\")\n","            f.write(f\"  法規節點: {stats['construction_stats'].get('regulation', 0)} 個\\n\")\n","\n","            if self.strict_mode and self.filtered_nodes:\n","                f.write(f\"  過濾無效節點: {len(self.filtered_nodes)} 個\\n\")\n","                f.write(\"    (主要原因: LLM 拒絕回答、資料缺失、格式錯誤)\\n\")\n","            f.write(\"\\n\")\n","\n","            # 6. 圖結構健康度檢查\n","            f.write(\"【六】圖結構健康度檢查\\n\")\n","\n","            # 檢查孤立節點\n","            isolated = [n for n in self.graph.nodes() if self.graph.degree(n) == 0]\n","            f.write(f\"  孤立節點數: {len(isolated)} 個\")\n","            if len(isolated) > 0:\n","                f.write(\" ⚠️ 建議檢查資料完整性\\n\")\n","            else:\n","                f.write(\" ✓\\n\")\n","\n","            # 檢查 Incident 節點的連通性\n","            incident_nodes = [n for n, d in self.graph.nodes(data=True)\n","                            if d.get('node_type') == 'Incident']\n","            incidents_with_causes = sum(1 for inc in incident_nodes\n","                                       if any(d.get('relation') == EDGE_HAS_CAUSE\n","                                             for _, _, d in self.graph.in_edges(inc, data=True)))\n","\n","            f.write(f\"  有因果鏈的事件: {incidents_with_causes}/{len(incident_nodes)} \")\n","            coverage = incidents_with_causes / len(incident_nodes) if incident_nodes else 0\n","            if coverage > 0.8:\n","                f.write(\"✓\\n\")\n","            elif coverage > 0.5:\n","                f.write(\"⚠️ 部分事件缺少原因分析\\n\")\n","            else:\n","                f.write(\"❌ 多數事件缺少原因分析\\n\")\n","\n","            # 檢查推理路徑完整性\n","            complete_paths = 0\n","            for inc in incident_nodes:\n","                # 檢查是否存在 Incident -> ... -> Regulation 的完整路徑\n","                regulations = [n for n in nx.descendants(self.graph, inc)\n","                             if self.graph.nodes[n].get('node_type') == 'Regulation']\n","                if regulations:\n","                    complete_paths += 1\n","\n","            f.write(f\"  有完整推理路徑的事件: {complete_paths}/{len(incident_nodes)} \")\n","            path_coverage = complete_paths / len(incident_nodes) if incident_nodes else 0\n","            if path_coverage > 0.9:\n","                f.write(\"✓\\n\")\n","            elif path_coverage > 0.7:\n","                f.write(\"⚠️\\n\")\n","            else:\n","                f.write(\"❌ 推理路徑構建不完整\\n\")\n","            f.write(\"\\n\")\n","\n","            # 7. 隨機抽樣事件路徑範例\n","            f.write(\"【七】事件推理路徑範例（隨機抽樣 3 個）\\n\")\n","            import random\n","            sample_incidents = random.sample(incident_nodes, min(3, len(incident_nodes)))\n","\n","            for idx, inc_id in enumerate(sample_incidents, 1):\n","                f.write(f\"\\n--- 範例 {idx} ---\\n\")\n","                inc_data = self.graph.nodes[inc_id]\n","                f.write(f\"事件: {inc_data.get('label', 'Unknown')}\\n\")\n","                f.write(f\"產業: {inc_data.get('industry', 'Unknown')}\\n\")\n","                f.write(f\"類型: {inc_data.get('incident_type', 'Unknown')}\\n\\n\")\n","\n","                # 追溯因果鏈\n","                f.write(\"【因果鏈追溯】\\n\")\n","                cause_chain = []\n","                for pred in self.graph.predecessors(inc_id):\n","                    pred_data = self.graph.nodes[pred]\n","                    if 'Cause' in pred_data.get('node_type', ''):\n","                        cause_chain.append((pred, pred_data))\n","\n","                        # 繼續往回追\n","                        for ppred in self.graph.predecessors(pred):\n","                            ppred_data = self.graph.nodes[ppred]\n","                            if 'Cause' in ppred_data.get('node_type', ''):\n","                                cause_chain.append((ppred, ppred_data))\n","\n","                # 按層級排序\n","                cause_order = {'Cause_Basic': 1, 'Cause_Indirect': 2, 'Cause_Direct': 3}\n","                cause_chain.sort(key=lambda x: cause_order.get(x[1].get('node_type', ''), 0))\n","\n","                for cid, cdata in cause_chain:\n","                    level = cdata.get('cause_level', 'unknown')\n","                    f.write(f\"  [{level:8s}] {cdata.get('label', '')[:80]}\\n\")\n","\n","                if not cause_chain:\n","                    f.write(\"  (無因果鏈資料)\\n\")\n","\n","                # 違規行為\n","                f.write(\"\\n【違規行為】\\n\")\n","                violations = []\n","                for desc in nx.descendants(self.graph, inc_id):\n","                    desc_data = self.graph.nodes[desc]\n","                    if desc_data.get('node_type') == 'Violation':\n","                        violations.append(desc_data.get('label', ''))\n","\n","                if violations:\n","                    for v in violations:\n","                        f.write(f\"  • {v}\\n\")\n","                else:\n","                    f.write(\"  (無明確違規項目)\\n\")\n","\n","                # 相關法規\n","                f.write(\"\\n【相關法規】\\n\")\n","                regulations = []\n","                for desc in nx.descendants(self.graph, inc_id):\n","                    desc_data = self.graph.nodes[desc]\n","                    if desc_data.get('node_type') == 'Regulation':\n","                        regulations.append(desc_data.get('label', ''))\n","\n","                if regulations:\n","                    for r in set(regulations):  # 去重\n","                        f.write(f\"  • {r}\\n\")\n","                else:\n","                    f.write(\"  (無相關法規)\\n\")\n","\n","                # 涉及媒介物\n","                f.write(\"\\n【涉及媒介物】\\n\")\n","                mediums = []\n","                for succ in self.graph.successors(inc_id):\n","                    succ_data = self.graph.nodes[succ]\n","                    if 'Medium' in succ_data.get('node_type', ''):\n","                        mediums.append(f\"{succ_data.get('node_type')}: {succ_data.get('label')}\")\n","\n","                if mediums:\n","                    for m in mediums:\n","                        f.write(f\"  • {m}\\n\")\n","                else:\n","                    f.write(\"  (無媒介物資料)\\n\")\n","\n","                f.write(\"\\n\")\n","\n","        print(f\"✓ 可讀報告已匯出至: {filepath}\")\n","\n","    def save_graph(self, output_path: str, format: str = 'graphml'):\n","        \"\"\"\n","        儲存圖譜\n","\n","        Args:\n","            output_path: 輸出路徑\n","            format: 格式 (graphml, gexf, json)\n","        \"\"\"\n","        if format == 'graphml':\n","            nx.write_graphml(self.graph, output_path)\n","        elif format == 'gexf':\n","            nx.write_gexf(self.graph, output_path)\n","        elif format == 'json':\n","            from networkx.readwrite import json_graph\n","            data = json_graph.node_link_data(self.graph)\n","            with open(output_path, 'w', encoding='utf-8') as f:\n","                json.dump(data, f, ensure_ascii=False, indent=2)\n","        else:\n","            raise ValueError(f\"不支援的格式: {format}\")\n","\n","        print(f\"✓ 圖譜已儲存至: {output_path} (格式: {format})\")\n","\n","    def export_for_gnn(self, output_path: str):\n","        \"\"\"\n","        匯出為 PyTorch Geometric 友好格式\n","\n","        包含:\n","        - edge_index: 邊列表\n","        - node_features: 節點特徵 (需後續用 BERT 補充)\n","        - edge_types: 邊類型 (用於異質圖學習)\n","        - metadata: 節點與邊的元資料\n","        \"\"\"\n","        import pickle\n","\n","        # 節點映射\n","        node_to_idx = {node: idx for idx, node in enumerate(self.graph.nodes())}\n","        idx_to_node = {v: k for k, v in node_to_idx.items()}\n","\n","        # 邊列表與邊類型\n","        edge_index = []\n","        edge_types = []\n","        edge_relation_to_id = {}\n","\n","        for u, v, data in self.graph.edges(data=True):\n","            relation = data.get('relation', 'Unknown')\n","\n","            # 為每種關係分配 ID\n","            if relation not in edge_relation_to_id:\n","                edge_relation_to_id[relation] = len(edge_relation_to_id)\n","\n","            edge_index.append([node_to_idx[u], node_to_idx[v]])\n","            edge_types.append(edge_relation_to_id[relation])\n","\n","        # 節點特徵 (簡單 one-hot，實際應用中應使用 BERT embeddings)\n","        node_type_to_id = {}\n","        node_features = []\n","        node_type_ids = []\n","\n","        for node in self.graph.nodes():\n","            node_data = self.graph.nodes[node]\n","            node_type = node_data.get('node_type', 'Unknown')\n","\n","            if node_type not in node_type_to_id:\n","                node_type_to_id[node_type] = len(node_type_to_id)\n","\n","            node_type_ids.append(node_type_to_id[node_type])\n","\n","            # 簡單特徵 (實際應該用 BERT)\n","            feature = [0] * len(node_type_to_id)\n","            feature[node_type_to_id[node_type]] = 1\n","            node_features.append(feature)\n","\n","        # 元資料\n","        metadata = {\n","            'node_labels': [self.graph.nodes[node].get('label', '')\n","                          for node in self.graph.nodes()],\n","            'node_types': [self.graph.nodes[node].get('node_type', 'Unknown')\n","                         for node in self.graph.nodes()],\n","            'edge_relations': [self.graph.edges[u, v, k].get('relation', 'Unknown')\n","                             for u, v, k in self.graph.edges(keys=True)]\n","        }\n","\n","        graph_data = {\n","            'edge_index': edge_index,\n","            'edge_types': edge_types,\n","            'node_features': node_features,\n","            'node_type_ids': node_type_ids,\n","            'node_to_idx': node_to_idx,\n","            'idx_to_node': idx_to_node,\n","            'edge_relation_to_id': edge_relation_to_id,\n","            'node_type_to_id': node_type_to_id,\n","            'metadata': metadata,\n","            'num_nodes': len(node_to_idx),\n","            'num_edges': len(edge_index),\n","            'num_edge_types': len(edge_relation_to_id),\n","            'num_node_types': len(node_type_to_id)\n","        }\n","\n","        with open(output_path, 'wb') as f:\n","            pickle.dump(graph_data, f)\n","\n","        print(f\"✓ GNN 格式已匯出至: {output_path}\")\n","        print(f\"  節點數: {graph_data['num_nodes']}\")\n","        print(f\"  邊數: {graph_data['num_edges']}\")\n","        print(f\"  邊類型數: {graph_data['num_edge_types']}\")\n","        print(f\"  節點類型數: {graph_data['num_node_types']}\")\n","\n","    def export_for_llm_training(self, output_path: str):\n","        \"\"\"\n","        匯出為 LLM 訓練友好格式 (JSON Lines)\n","\n","        每一行是一個訓練樣本，包含:\n","        - incident: 事件描述\n","        - reasoning_path: 推理路徑 (Cause -> Violation -> Regulation)\n","        - context: 相關情境 (產業、媒介物等)\n","        \"\"\"\n","        training_samples = []\n","\n","        incident_nodes = [n for n, d in self.graph.nodes(data=True)\n","                         if d.get('node_type') == 'Incident']\n","\n","        for inc_id in incident_nodes:\n","            inc_data = self.graph.nodes[inc_id]\n","\n","            # 構建推理路徑\n","            reasoning_path = {\n","                'causes': [],\n","                'violations': [],\n","                'regulations': []\n","            }\n","\n","            # 收集原因\n","            for pred in self.graph.predecessors(inc_id):\n","                pred_data = self.graph.nodes[pred]\n","                if 'Cause' in pred_data.get('node_type', ''):\n","                    reasoning_path['causes'].append({\n","                        'level': pred_data.get('cause_level', 'unknown'),\n","                        'description': pred_data.get('label', '')\n","                    })\n","\n","                    # 繼續往回追\n","                    for ppred in self.graph.predecessors(pred):\n","                        ppred_data = self.graph.nodes[ppred]\n","                        if 'Cause' in ppred_data.get('node_type', ''):\n","                            reasoning_path['causes'].append({\n","                                'level': ppred_data.get('cause_level', 'unknown'),\n","                                'description': ppred_data.get('label', '')\n","                            })\n","\n","            # 收集違規與法規\n","            for desc in nx.descendants(self.graph, inc_id):\n","                desc_data = self.graph.nodes[desc]\n","                node_type = desc_data.get('node_type', '')\n","\n","                if node_type == 'Violation':\n","                    reasoning_path['violations'].append({\n","                        'description': desc_data.get('label', ''),\n","                        'actor': desc_data.get('actor', 'unknown')\n","                    })\n","                elif node_type == 'Regulation':\n","                    reasoning_path['regulations'].append({\n","                        'law_name': desc_data.get('law_name', ''),\n","                        'article': desc_data.get('article', ''),\n","                        'full_text': desc_data.get('label', '')\n","                    })\n","\n","            # 收集情境\n","            context = {\n","                'industry': inc_data.get('industry', 'Unknown'),\n","                'incident_type': inc_data.get('incident_type', 'Unknown'),\n","                'mediums': []\n","            }\n","\n","            for succ in self.graph.successors(inc_id):\n","                succ_data = self.graph.nodes[succ]\n","                if 'Medium' in succ_data.get('node_type', ''):\n","                    context['mediums'].append({\n","                        'type': succ_data.get('node_type', ''),\n","                        'name': succ_data.get('label', '')\n","                    })\n","\n","            # 構建訓練樣本\n","            sample = {\n","                'id': inc_id,\n","                'incident': {\n","                    'description': inc_data.get('full_text', ''),\n","                    'summary': inc_data.get('label', '')\n","                },\n","                'reasoning_path': reasoning_path,\n","                'context': context\n","            }\n","\n","            training_samples.append(sample)\n","\n","        # 寫入 JSON Lines\n","        with open(output_path, 'w', encoding='utf-8') as f:\n","            for sample in training_samples:\n","                f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n","\n","        print(f\"✓ LLM 訓練格式已匯出至: {output_path}\")\n","        print(f\"  訓練樣本數: {len(training_samples)}\")\n","\n","    def export_excel_summary(self, output_path: str):\n","        \"\"\"\n","        匯出 Excel 格式的圖譜摘要 (需要 pandas 和 openpyxl)\n","\n","        包含多個工作表:\n","        1. 節點列表\n","        2. 邊列表\n","        3. 統計資訊\n","        4. 法規排名\n","        \"\"\"\n","        try:\n","            import pandas as pd\n","\n","            # 工作表 1: 節點列表\n","            nodes_data = []\n","            for node, data in self.graph.nodes(data=True):\n","                nodes_data.append({\n","                    'Node_ID': node,\n","                    'Type': data.get('node_type', ''),\n","                    'Label': data.get('label', ''),\n","                    'In_Degree': self.graph.in_degree(node),\n","                    'Out_Degree': self.graph.out_degree(node),\n","                    'Industry': data.get('industry', ''),\n","                    'Code': data.get('code', '')\n","                })\n","\n","            df_nodes = pd.DataFrame(nodes_data)\n","\n","            # 工作表 2: 邊列表\n","            edges_data = []\n","            for u, v, data in self.graph.edges(data=True):\n","                u_label = self.graph.nodes[u].get('label', u)[:50]\n","                v_label = self.graph.nodes[v].get('label', v)[:50]\n","                edges_data.append({\n","                    'Source': u,\n","                    'Source_Label': u_label,\n","                    'Target': v,\n","                    'Target_Label': v_label,\n","                    'Relation': data.get('relation', ''),\n","                    'Weight': data.get('weight', 1.0)\n","                })\n","\n","            df_edges = pd.DataFrame(edges_data)\n","\n","            # 工作表 3: 統計資訊\n","            stats = self.get_statistics()\n","            stats_data = [\n","                {'指標': '總節點數', '數值': stats['total_nodes']},\n","                {'指標': '總邊數', '數值': stats['total_edges']},\n","                {'指標': '圖密度', '數值': f\"{stats['graph_density']:.6f}\"},\n","                {'指標': '是否連通', '數值': '是' if stats['is_connected'] else '否'}\n","            ]\n","\n","            for ntype, count in stats['node_type_distribution'].items():\n","                stats_data.append({'指標': f'節點類型: {ntype}', '數值': count})\n","\n","            df_stats = pd.DataFrame(stats_data)\n","\n","            # 工作表 4: 法規排名\n","            regs_data = []\n","            for reg_id, freq in stats['most_cited_regulations']:\n","                if reg_id in self.graph:\n","                    reg_label = self.graph.nodes[reg_id].get('label', reg_id)\n","                    regs_data.append({\n","                        'Regulation_ID': reg_id,\n","                        'Label': reg_label,\n","                        'Citation_Count': freq\n","                    })\n","\n","            df_regs = pd.DataFrame(regs_data)\n","\n","            # 寫入 Excel\n","            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n","                df_nodes.to_excel(writer, sheet_name='節點列表', index=False)\n","                df_edges.to_excel(writer, sheet_name='邊列表', index=False)\n","                df_stats.to_excel(writer, sheet_name='統計資訊', index=False)\n","                df_regs.to_excel(writer, sheet_name='法規排名', index=False)\n","\n","            print(f\"✓ Excel 報告已匯出至: {output_path}\")\n","\n","        except ImportError:\n","            print(\"❌ 錯誤: 需要安裝 pandas 和 openpyxl 才能匯出 Excel 格式\")\n","            print(\"   請執行: pip install pandas openpyxl\")\n","\n","\n","def main():\n","    \"\"\"\n","    主執行函式\n","\n","    示範如何使用 OccupationalSafetyKnowledgeGraph 建構知識圖譜\n","    並匯出多種格式供不同用途使用\n","    \"\"\"\n","\n","    parser = argparse.ArgumentParser(description=\"Build Occupational Safety Knowledge Graph (V2)\")\n","\n","    ## input directory setting\n","    parser.add_argument(\"--input\", \"-i\",\n","                        default=os.environ.get(\"OSH_INPUT\", \"osh_doc_merged.json\"),\n","                        help=\"輸入事故 JSON 檔案 (預設: osh_doc_merged.json)\")\n","    parser.add_argument(\"--out-dir\", \"-o\",\n","                        default=os.environ.get(\"OSH_OUT_DIR\", \"./output\"),\n","                        help=\"輸出資料夾 (預設: ./output)\")\n","    parser.add_argument(\"--strict\", action=\"store_true\",\n","                        default=os.environ.get(\"OSH_STRICT\", \"1\") != \"0\",\n","                        help=\"啟用嚴格模式 (預設: 開啟)\")\n","    parser.add_argument(\"--no-semantic\", action=\"store_true\",\n","                        help=\"停用語義比對\")\n","\n","    # 修改這裡：在 Notebook 中執行時，強制傳入空參數列表，\n","    # 避免抓到 Jupyter 的 kernel 參數 (-f ...)\n","    args = parser.parse_args(args=[])\n","\n","    input_path = Path(args.input)\n","    out_dir = Path(args.out_dir)\n","    out_dir.mkdir(parents=True, exist_ok=True)\n","\n","    print(\"=\" * 80)\n","    print(\"台灣職業安全法律知識圖譜建構系統 V2\")\n","    print(f\"輸入檔案: {input_path}\")\n","    print(f\"輸出資料夾: {out_dir}\")\n","    print(\"=\" * 80)\n","    print()\n","\n","    # === 1. 載入資料 ===\n","    print(\"【步驟 1】載入事故資料...\")\n","    try:\n","        with input_path.open('r', encoding='utf-8') as f:\n","            incidents_data = json.load(f)\n","        print(f\"✓ 成功載入 {len(incidents_data)} 筆事故資料\\n\")\n","    except FileNotFoundError:\n","        print(f\"❌ 錯誤: 找不到 '{input_path}'\")\n","        return\n","    except json.JSONDecodeError:\n","        print(\"❌ 錯誤: JSON 格式錯誤\")\n","        return\n","\n","    # === 2. 建構知識圖譜 ===\n","    print(\"【步驟 2】建構知識圖譜...\")\n","    print(f\"  嚴格模式: {args.strict}\")\n","    print(f\"  語義分析: {not args.no_semantic}\\n\")\n","\n","    kg_builder = OccupationalSafetyKnowledgeGraph(\n","        strict_mode=args.strict,\n","        enable_semantic=not args.no_semantic\n","    )\n","\n","    graph = kg_builder.build_graph(incidents_data)\n","\n","    # === 3. 輸出統計資訊 ===\n","    print(\"\\n【步驟 3】分析圖譜統計資訊...\")\n","    stats = kg_builder.get_statistics()\n","\n","    print(f\"\\n圖譜規模:\")\n","    print(f\"  節點: {stats['total_nodes']:,}\")\n","    print(f\"  邊: {stats['total_edges']:,}\")\n","    print(f\"  密度: {stats['graph_density']:.6f}\")\n","\n","    print(f\"\\n核心節點類型:\")\n","    for ntype in ['Incident', 'Cause_Direct', 'Cause_Indirect', 'Cause_Basic',\n","                  'Violation', 'Regulation']:\n","        count = stats['node_type_distribution'].get(ntype, 0)\n","        print(f\"  {ntype:20s}: {count:5d}\")\n","\n","    print(f\"\\n關鍵邊類型 (推理路徑):\")\n","    for rel in [EDGE_HAS_CAUSE, EDGE_ENABLED_BY, EDGE_LEADS_TO, EDGE_VIOLATES]:\n","        count = stats['edge_relation_distribution'].get(rel, 0)\n","        print(f\"  {rel:20s}: {count:5d}\")\n","\n","    # === 4. 匯出多種格式 ===\n","    print(\"\\n【步驟 4】匯出多種格式...\")\n","\n","    ## output directory setting\n","    out_report = out_dir / 'knowledge_graph_report.txt'\n","    out_gnn = out_dir / 'knowledge_graph_gnn.pkl'\n","    out_llm = out_dir / 'knowledge_graph_llm_training.jsonl'\n","    out_graphml = out_dir / 'knowledge_graph.graphml'\n","    out_json = out_dir / 'knowledge_graph.json'\n","    out_excel = out_dir / 'knowledge_graph_summary.xlsx'\n","    out_stats = out_dir / 'knowledge_graph_stats.json'\n","\n","    # 4.1 人類可讀的 TXT 報告\n","    print(f\"\\n  [1/6] 匯出可讀報告 -> {out_report}\")\n","    kg_builder.export_readable_summary(str(out_report))\n","\n","    # 4.2 GNN 訓練格式\n","    print(f\"\\n  [2/6] 匯出 GNN 格式 -> {out_gnn}\")\n","    kg_builder.export_for_gnn(str(out_gnn))\n","\n","    # 4.3 LLM 訓練格式\n","    print(f\"\\n  [3/6] 匯出 LLM 訓練格式 -> {out_llm}\")\n","    kg_builder.export_for_llm_training(str(out_llm))\n","\n","    # 4.4 標準圖格式 (GraphML, JSON)\n","    print(f\"\\n  [4/6] 匯出標準圖格式 -> {out_graphml}, {out_json}\")\n","    kg_builder.save_graph(str(out_graphml), format='graphml')\n","    kg_builder.save_graph(str(out_json), format='json')\n","\n","    # 4.5 Excel 報告 (需要 pandas)\n","    print(f\"\\n  [5/6] 匯出 Excel 報告 -> {out_excel}\")\n","    try:\n","        kg_builder.export_excel_summary(str(out_excel))\n","    except Exception:\n","        print(\"     ⚠️ 跳過 Excel 匯出 (需安裝 pandas 和 openpyxl)\")\n","\n","    # 4.6 完整統計 JSON\n","    print(f\"\\n  [6/6] 匯出完整統計 -> {out_stats}\")\n","    with out_stats.open('w', encoding='utf-8') as f:\n","        json.dump(stats, f, ensure_ascii=False, indent=2)\n","    print(f\"     ✓ 已匯出至: {out_stats}\")\n","\n","    # === 5. 品質檢查報告 ===\n","    print(\"\\n【步驟 5】品質檢查...\")\n","\n","    if kg_builder.strict_mode and kg_builder.filtered_nodes:\n","        print(f\"  過濾了 {len(kg_builder.filtered_nodes)} 個無效節點\")\n","\n","        # 統計過濾原因\n","        filter_reasons = defaultdict(int)\n","        for _, _, reason in kg_builder.filtered_nodes:\n","            filter_reasons[reason] += 1\n","\n","        print(\"  過濾原因分布:\")\n","        for reason, count in filter_reasons.items():\n","            print(f\"    {reason:25s}: {count:4d} 個\")\n","\n","    # === 完成 ===\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"✓ 全部完成!\")\n","    print(\"=\" * 80)\n","\n","    print(\"\\n建議查看順序:\")\n","    print(f\"  1️⃣  {out_report}\")\n","    print(\"       → 完整的品質報告,包含統計、範例、健康度檢查\")\n","    print()\n","    print(f\"  2️⃣  {out_excel} (如有)\")\n","    print(\"       → Excel 格式,可用於進一步分析\")\n","    print()\n","    print(f\"  3️⃣  {out_llm}\")\n","    print(\"       → 用於訓練大型語言模型的推理資料\")\n","    print()\n","    print(f\"  4️⃣  {out_gnn}\")\n","    print(\"       → 用於訓練圖神經網路\")\n","    print()\n","\n","    print(\"\\n用途說明:\")\n","    print(\"  • 訓練 LLM 法律推理能力:\")\n","    print(f\"    → 使用 {out_llm}\")\n","    print(\"    → 每個樣本包含完整的推理路徑 (Cause→Violation→Regulation)\")\n","    print()\n","    print(\"  • 訓練 GNN 預測模型:\")\n","    print(f\"    → 使用 {out_gnn}\")\n","    print(\"    → 支援異質圖採樣與多跳推理\")\n","    print()\n","    print(\"  • 視覺化與分析:\")\n","    print(f\"    → 使用 {out_graphml}\")\n","    print(\"    → 可用 Gephi, Cytoscape 等工具開啟\")\n","    print()\n"],"metadata":{"id":"WuKDWkjqhmwo","executionInfo":{"status":"ok","timestamp":1767165668489,"user_tz":-480,"elapsed":59,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKWp8MqghwmG","executionInfo":{"status":"ok","timestamp":1767165673214,"user_tz":-480,"elapsed":4719,"user":{"displayName":"黃旭寬","userId":"11829153694624127029"}},"outputId":"43482311-5c81-4809-97b0-5e4fa767b61f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","台灣職業安全法律知識圖譜建構系統 V2\n","輸入檔案: osh_doc_merged.json\n","輸出資料夾: output\n","================================================================================\n","\n","【步驟 1】載入事故資料...\n","✓ 成功載入 339 筆事故資料\n","\n","【步驟 2】建構知識圖譜...\n","  嚴格模式: True\n","  語義分析: True\n","\n","開始構建知識圖譜，共 339 筆事件...\n","嚴格模式: True, 語義分析: True\n","已處理 10/339 筆資料\n","已處理 20/339 筆資料\n","已處理 30/339 筆資料\n","已處理 40/339 筆資料\n","已處理 50/339 筆資料\n","已處理 60/339 筆資料\n","已處理 70/339 筆資料\n","已處理 80/339 筆資料\n","已處理 90/339 筆資料\n","已處理 100/339 筆資料\n","已處理 110/339 筆資料\n","已處理 120/339 筆資料\n","已處理 130/339 筆資料\n","已處理 140/339 筆資料\n","已處理 150/339 筆資料\n","已處理 160/339 筆資料\n","已處理 170/339 筆資料\n","已處理 180/339 筆資料\n","已處理 190/339 筆資料\n","已處理 200/339 筆資料\n","已處理 210/339 筆資料\n","已處理 220/339 筆資料\n","已處理 230/339 筆資料\n","已處理 240/339 筆資料\n","已處理 250/339 筆資料\n","已處理 260/339 筆資料\n","已處理 270/339 筆資料\n","已處理 280/339 筆資料\n","已處理 290/339 筆資料\n","已處理 300/339 筆資料\n","已處理 310/339 筆資料\n","已處理 320/339 筆資料\n","已處理 330/339 筆資料\n","\n","============================================================\n","圖譜構建完成:\n","  節點數: 1678\n","  邊數: 15188\n","  過濾節點數: 102\n","  (詳見 get_filtered_nodes() 方法)\n","============================================================\n","\n","\n","【步驟 3】分析圖譜統計資訊...\n","\n","圖譜規模:\n","  節點: 1,678\n","  邊: 15,188\n","  密度: 0.005397\n","\n","核心節點類型:\n","  Incident            :   276\n","  Cause_Direct        :   272\n","  Cause_Indirect      :     0\n","  Cause_Basic         :     1\n","  Violation           :   657\n","  Regulation          :   261\n","\n","關鍵邊類型 (推理路徑):\n","  HAS_CAUSE           :   276\n","  ENABLED_BY          :     0\n","  LEADS_TO            :  1356\n","  VIOLATES_LAW        : 12181\n","\n","【步驟 4】匯出多種格式...\n","\n","  [1/6] 匯出可讀報告 -> output/knowledge_graph_report.txt\n","✓ 可讀報告已匯出至: output/knowledge_graph_report.txt\n","\n","  [2/6] 匯出 GNN 格式 -> output/knowledge_graph_gnn.pkl\n","✓ GNN 格式已匯出至: output/knowledge_graph_gnn.pkl\n","  節點數: 1678\n","  邊數: 15188\n","  邊類型數: 7\n","  節點類型數: 10\n","\n","  [3/6] 匯出 LLM 訓練格式 -> output/knowledge_graph_llm_training.jsonl\n","✓ LLM 訓練格式已匯出至: output/knowledge_graph_llm_training.jsonl\n","  訓練樣本數: 276\n","\n","  [4/6] 匯出標準圖格式 -> output/knowledge_graph.graphml, output/knowledge_graph.json\n","✓ 圖譜已儲存至: output/knowledge_graph.graphml (格式: graphml)\n","✓ 圖譜已儲存至: output/knowledge_graph.json (格式: json)\n","\n","  [5/6] 匯出 Excel 報告 -> output/knowledge_graph_summary.xlsx\n","✓ Excel 報告已匯出至: output/knowledge_graph_summary.xlsx\n","\n","  [6/6] 匯出完整統計 -> output/knowledge_graph_stats.json\n","     ✓ 已匯出至: output/knowledge_graph_stats.json\n","\n","【步驟 5】品質檢查...\n","  過濾了 102 個無效節點\n","  過濾原因分布:\n","    invalid_keyword          :  102 個\n","\n","================================================================================\n","✓ 全部完成!\n","================================================================================\n","\n","建議查看順序:\n","  1️⃣  output/knowledge_graph_report.txt\n","       → 完整的品質報告,包含統計、範例、健康度檢查\n","\n","  2️⃣  output/knowledge_graph_summary.xlsx (如有)\n","       → Excel 格式,可用於進一步分析\n","\n","  3️⃣  output/knowledge_graph_llm_training.jsonl\n","       → 用於訓練大型語言模型的推理資料\n","\n","  4️⃣  output/knowledge_graph_gnn.pkl\n","       → 用於訓練圖神經網路\n","\n","\n","用途說明:\n","  • 訓練 LLM 法律推理能力:\n","    → 使用 output/knowledge_graph_llm_training.jsonl\n","    → 每個樣本包含完整的推理路徑 (Cause→Violation→Regulation)\n","\n","  • 訓練 GNN 預測模型:\n","    → 使用 output/knowledge_graph_gnn.pkl\n","    → 支援異質圖採樣與多跳推理\n","\n","  • 視覺化與分析:\n","    → 使用 output/knowledge_graph.graphml\n","    → 可用 Gephi, Cytoscape 等工具開啟\n","\n"]}]}]}