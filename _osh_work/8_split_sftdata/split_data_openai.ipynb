{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## æŠŠ sft_training_data_final.jsonl æ‹†æˆæ¸¬è©¦è·Ÿé©—è­‰é›†çš„åœ°æ–¹"
      ],
      "metadata": {
        "id": "qymfHRWc4skn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "xAp2Dl2fDvr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manually upload 'sft_training_data_final.jsonl'"
      ],
      "metadata": {
        "id": "yEjNPMVfRGsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# è¨­å®šå€\n",
        "# ==========================================\n",
        "INPUT_FILE = 'sft_training_data_final.jsonl'\n",
        "OUTPUT_DIR = 'split_dataset_smart'\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# ç›®æ¨™åˆ‡åˆ†æ•¸é‡\n",
        "TRAIN_SIZE = 300\n",
        "VAL_SIZE = 29\n",
        "TEST_SIZE = 40\n",
        "\n",
        "# æ‚¨çš„ OpenAI API Key\n",
        "# ç­–ç•¥ï¼šå„ªå…ˆè®€å–ç’°å¢ƒè®Šæ•¸ï¼Œè‹¥ç„¡å‰‡å˜—è©¦è®€å– Google Colab Secrets\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "    except ImportError:\n",
        "        # é Colab ç’°å¢ƒï¼Œå¿½ç•¥\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        # é›–ç„¶æ˜¯ Colab ä½†å¯èƒ½æ²’è¨­ Secretï¼Œæˆ–è€… Key åç¨±ä¸å°\n",
        "        print(f\"æç¤º: æœªå¾ Colab Secret è®€å–åˆ° 'OPENAI_API_KEY'ã€‚è‹¥æœ‰éœ€è¦è«‹åœ¨å´æ¬„ 'ğŸ”‘' è¨­å®šã€‚\")\n",
        "\n",
        "# å®šç¾©è·ç½é¡åˆ¥æ¨™ç±¤ (è®“ LLM å¾ä¸­é¸æ“‡)\n",
        "INCIDENT_CATEGORIES = [\n",
        "    \"å¢œè½ã€æ»¾è½\",       #\n",
        "    \"è·Œå€’\",             #\n",
        "    \"è¡æ’\",             # (æŒ‡äººé«”ä»¥è‡ªèº«å‹•åŠ›ç¢°æ’ç‰©é«”)\n",
        "    \"ç‰©é«”é£›è½\",         #\n",
        "    \"ç‰©é«”å€’å¡Œã€å´©å¡Œ\",   #\n",
        "    \"è¢«æ’\",             # (æŒ‡äººé«”è¢«é£›ä¾†ã€è½ä¸‹ã€æ»‘å‹•ä¹‹ç‰©é«”æ“Šä¸­)\n",
        "    \"è¢«å¤¾ã€è¢«æ²\",       #\n",
        "    \"è¢«åˆ‡ã€å‰²ã€æ“¦å‚·\",   #\n",
        "    \"è¸©è¸\",             #\n",
        "    \"æººæ–ƒ\",             #\n",
        "    \"èˆ‡é«˜æº«ã€ä½æº«æ¥è§¸\", #\n",
        "    \"èˆ‡æœ‰å®³ç‰©ç­‰ä¹‹æ¥è§¸\", # (å«å¸å…¥ä¸­æ¯’)\n",
        "    \"æ„Ÿé›»\",             #\n",
        "    \"çˆ†ç‚¸\",             #\n",
        "    \"ç‰©é«”ç ´è£‚\",         #\n",
        "    \"ç«ç½\",             #\n",
        "    \"ä¸ç•¶å‹•ä½œ\",         #\n",
        "    \"äº¤é€šäº‹æ•…\",         # åˆä½µ (å…¬è·¯ã€éµè·¯ã€èˆ¹èˆ¶ç­‰)\n",
        "    \"å…¶ä»–\"              # (ç„¡æ³•æ­¸é¡)\n",
        "]"
      ],
      "metadata": {
        "id": "CptE0bIJB7mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_for_preview(text):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ Regex å¼·åŠ›æ¸…æ´—ï¼š\n",
        "    1. å»é™¤æ‰€æœ‰éä¸­æ–‡å­—ç¬¦ (å»é™¤æ¨™é»ã€æ•¸å­—ã€è‹±æ–‡)\n",
        "    2. å»é™¤ 'â—‹' (å»è­˜åˆ¥åŒ–ç¬¦è™Ÿ)\n",
        "    3. å»é™¤å¸¸è¦‹ç„¡æ„ç¾©è©\n",
        "    \"\"\"\n",
        "    # åƒ…ä¿ç•™ä¸­æ–‡å­— (\\u4e00-\\u9fa5)\n",
        "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
        "    # å»é™¤ç‰¹å®šé›œè¨Šå­—\n",
        "    text = re.sub(r'[â—‹oO]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "JgjeK09OCARM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_from_openai(text, client):\n",
        "    \"\"\"\n",
        "    å‘¼å« OpenAI APIï¼Œä¾æ“šå®˜æ–¹ã€Œç½å®³é¡å‹ã€ä»£è™Ÿè¡¨é€²è¡Œç²¾æº–åˆ†é¡ã€‚\n",
        "    \"\"\"\n",
        "    snippet = text[:600] # ç¨å¾®å¢åŠ é•·åº¦ä»¥åŒ…å«æ›´å¤šæƒ…å¢ƒ\n",
        "\n",
        "    # System Prompt: è³¦äºˆå°ˆå®¶è§’è‰²ï¼Œä¸¦çµ¦äºˆåš´æ ¼çš„åˆ†é¡æŒ‡å°\n",
        "    # é€™è£¡çš„ Prompt è¨­è¨ˆæ˜¯ç‚ºäº†é˜²æ­¢ LLM æ··æ·†ã€Œåª’ä»‹ç‰©ã€èˆ‡ã€Œç½å®³é¡å‹ã€\n",
        "    system_prompt = \"\"\"\n",
        "    ä½ æ˜¯ä¸€ä½ç²¾é€šå°ç£è·æ¥­å®‰å…¨æ³•è¦çš„å°ˆå®¶ã€‚è«‹ä¾æ“šã€Œè·æ¥­ç½å®³é¡å‹åˆ†é¡è¡¨ã€å°äº‹æ•…é€²è¡Œåˆ†é¡ã€‚\n",
        "\n",
        "    ã€é‡è¦åŸå‰‡ã€‘\n",
        "    1. è«‹å€åˆ†ã€Œåª’ä»‹ç‰©ã€èˆ‡ã€Œç½å®³é¡å‹ã€ã€‚ä¾‹å¦‚ï¼šè¢«ã€Œå †é«˜æ©Ÿã€æ’åˆ°ï¼Œç½å®³é¡å‹æ‡‰é¸ã€Œè¢«æ’ã€ï¼Œè€Œéå…¶ä»–ã€‚\n",
        "    2. ã€Œè¡æ’ã€æŒ‡äººå»æ’ç‰©é«”ï¼›ã€Œè¢«æ’ã€æŒ‡ç‰©é«”ä¾†æ’äººã€‚\n",
        "    3. è‹¥æ¶‰åŠå¢œè½ï¼Œå„ªå…ˆé¸æ“‡ã€Œå¢œè½ã€æ»¾è½ã€ã€‚\n",
        "    4. è‹¥æ¶‰åŠè§¸é›»ï¼Œé¸æ“‡ã€Œæ„Ÿé›»ã€ã€‚\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    è«‹é–±è®€ä»¥ä¸‹è·ç½äº‹æ•…æè¿°ï¼Œä¸¦å¾ä¸‹åˆ—æ¨™æº–æ¸…å–®ä¸­ï¼Œé¸å‡ºæœ€ä¸»è¦çš„ä¸€å€‹ã€Œç½å®³é¡å‹ã€ï¼š\n",
        "\n",
        "    {json.dumps(INCIDENT_CATEGORIES, ensure_ascii=False)}\n",
        "\n",
        "    äº‹æ•…æè¿°ï¼š\n",
        "    {snippet}\n",
        "\n",
        "    è«‹ç›´æ¥è¼¸å‡ºé¡åˆ¥åç¨±ï¼ˆä¾‹å¦‚ï¼šè¢«å¤¾ã€è¢«æ²ï¼‰ï¼Œä¸è¦è¼¸å‡ºä»»ä½•è§£é‡‹æˆ–å…¶ä»–æ–‡å­—ã€‚\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.0 # è¨­ç‚º 0 ç¢ºä¿åˆ†é¡çµæœç©©å®š\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"API Error: {e}\")\n",
        "        return \"å…¶ä»–\""
      ],
      "metadata": {
        "id": "8hh3p2JjERht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # æª¢æŸ¥ API Key\n",
        "    # å„ªå…ˆä½¿ç”¨å…¨åŸŸè®Šæ•¸ (ä¾†è‡ª os.getenv)ï¼Œè‹¥ç„¡å‰‡å†æ¬¡å˜—è©¦è®€å– env (ä»¥é˜²è¨­å®šé †åºå•é¡Œ)\n",
        "    api_key = OPENAI_API_KEY or os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    if not api_key or \"sk-\" not in api_key:\n",
        "        print(\"éŒ¯èª¤ï¼šè«‹è¨­å®šæ­£ç¢ºçš„ OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œå¦å‰‡ç„¡æ³•é€²è¡Œæ™ºæ…§åˆ†é¡ã€‚\")\n",
        "        print(\"æç¤ºï¼šæ‚¨å¯ä»¥ä½¿ç”¨ export OPENAI_API_KEY='sk-...' ä¾†è¨­å®š\")\n",
        "        return\n",
        "\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    # 1. è®€å–è³‡æ–™\n",
        "    print(f\"æ­£åœ¨è®€å– {INPUT_FILE}...\")\n",
        "    data = []\n",
        "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                data.append(json.loads(line))\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 2. AI æ™ºæ…§åˆ†é¡ (å¦‚æœå·²ç¶“è·‘éï¼Œå»ºè­°æŠŠçµæœå­˜æˆæš«å­˜æª”ï¼ŒçœéŒ¢)\n",
        "    # é€™è£¡æˆ‘å€‘å»ºç«‹ä¸€å€‹ cache æ©Ÿåˆ¶\n",
        "    cache_file = \"incident_categories_cache.json\"\n",
        "\n",
        "    if os.path.exists(cache_file):\n",
        "        print(\"åµæ¸¬åˆ°åˆ†é¡å¿«å–æª”ï¼Œæ­£åœ¨è¼‰å…¥...\")\n",
        "        with open(cache_file, 'r', encoding='utf-8') as f:\n",
        "            categories = json.load(f)\n",
        "    else:\n",
        "        print(f\"é–‹å§‹å‘¼å« OpenAI API å° {len(df)} ç­†è³‡æ–™é€²è¡Œåˆ†é¡ (é è¨ˆèŠ±è²» < $0.1 USD)...\")\n",
        "        categories = []\n",
        "        for i, row in df.iterrows():\n",
        "            if i % 10 == 0: print(f\"é€²åº¦: {i}/{len(df)}\")\n",
        "            cat = get_category_from_openai(row['input'], client)\n",
        "            # ç°¡å–®æ¸…æ´—å›å‚³çµæœ (é¿å… LLM å¤šè©±)\n",
        "            found_cat = \"å…¶ä»–\"\n",
        "            for valid_cat in INCIDENT_CATEGORIES:\n",
        "                if valid_cat in cat:\n",
        "                    found_cat = valid_cat\n",
        "                    break\n",
        "            categories.append(found_cat)\n",
        "\n",
        "        # å­˜æª”\n",
        "        with open(cache_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(categories, f, ensure_ascii=False)\n",
        "\n",
        "    df['category'] = categories\n",
        "\n",
        "    # 3. é¡¯ç¤ºåˆ†é¡çµæœçµ±è¨ˆ\n",
        "    print(\"\\n[AI åˆ¤æ–·] è·ç½é¡å‹åˆ†ä½ˆï¼š\")\n",
        "    print(df['category'].value_counts())\n",
        "\n",
        "    # 4. åˆ†å±¤åˆ‡åˆ† (Stratified Split)\n",
        "    # é€™æ˜¯æœ€é—œéµçš„ä¸€æ­¥ï¼šä¿è­‰ Train/Val/Test éƒ½æœ‰å„ç¨®ç½å®³\n",
        "\n",
        "    print(\"\\næ­£åœ¨é€²è¡Œåˆ†å±¤åˆ‡åˆ†...\")\n",
        "\n",
        "    # ç¬¬ä¸€åˆ€ï¼šåˆ‡å‡º Train (300)\n",
        "    # æ³¨æ„ï¼šå¦‚æœæŸå€‹é¡åˆ¥åªæœ‰ 1 ç­†ï¼Œstratify æœƒå ±éŒ¯ï¼Œæ‰€ä»¥éœ€è¦éæ¿¾æˆ–é€€åŒ–è™•ç†\n",
        "    try:\n",
        "        df_train, df_temp = train_test_split(\n",
        "            df,\n",
        "            train_size=TRAIN_SIZE,\n",
        "            stratify=df['category'],\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"è­¦å‘Šï¼šæŸäº›é¡åˆ¥æ¨£æœ¬å¤ªå°‘ï¼Œç„¡æ³•å®Œç¾åˆ†å±¤ã€‚è½‰ç‚ºéš¨æ©Ÿåˆ‡åˆ†ã€‚(éŒ¯èª¤: {e})\")\n",
        "        df_train, df_temp = train_test_split(df, train_size=TRAIN_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "    # ç¬¬äºŒåˆ€ï¼šåˆ‡å‡º Test (40) å’Œ Val (29)\n",
        "    try:\n",
        "        df_test, df_val = train_test_split(\n",
        "            df_temp,\n",
        "            train_size=TEST_SIZE, # çµ•å°æ•¸å­— 40\n",
        "            stratify=df_temp['category'],\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "    except ValueError:\n",
        "        print(\"è­¦å‘Šï¼šå‰©é¤˜è³‡æ–™é¡åˆ¥åˆ†ä½ˆç¨€ç–ï¼Œç¬¬äºŒéšæ®µè½‰ç‚ºéš¨æ©Ÿåˆ‡åˆ†ã€‚\")\n",
        "        df_test, df_val = train_test_split(\n",
        "            df_temp,\n",
        "            train_size=TEST_SIZE,\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "    # 5. è¼¸å‡ºçµæœèˆ‡å„²å­˜\n",
        "    if not os.path.exists(OUTPUT_DIR):\n",
        "        os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "    def save_split(df_split, name):\n",
        "        path = os.path.join(OUTPUT_DIR, name)\n",
        "        # ç§»é™¤æš«å­˜çš„ category æ¬„ä½ï¼Œä¿æŒåŸå§‹æ ¼å¼\n",
        "        records = df_split.drop(columns=['category']).to_dict('records')\n",
        "        with open(path, 'w', encoding='utf-8') as f:\n",
        "            for r in records:\n",
        "                f.write(json.dumps(r, ensure_ascii=False) + '\\n')\n",
        "\n",
        "        # çµ±è¨ˆè©² Split çš„åˆ†ä½ˆçµ¦ä½¿ç”¨è€…çœ‹\n",
        "        print(f\"\\næª”æ¡ˆ: {name} ({len(records)} ç­†)\")\n",
        "        print(\"åˆ†ä½ˆæ¦‚æ³:\", df_split['category'].value_counts().to_dict())\n",
        "\n",
        "    save_split(df_train, 'train.jsonl')\n",
        "    save_split(df_val, 'val.jsonl')\n",
        "    save_split(df_test, 'test.jsonl')\n",
        "\n",
        "    print(f\"\\nå…¨éƒ¨å®Œæˆï¼æª”æ¡ˆå·²å„²å­˜æ–¼ {OUTPUT_DIR}/\")"
      ],
      "metadata": {
        "id": "8WWYk5DkGhCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ThRzVmGjMv",
        "outputId": "ed032ccf-578e-49fa-8c1d-b9cb819e1081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨è®€å– sft_training_data_final.jsonl...\n",
            "åµæ¸¬åˆ°åˆ†é¡å¿«å–æª”ï¼Œæ­£åœ¨è¼‰å…¥...\n",
            "\n",
            "[AI åˆ¤æ–·] è·ç½é¡å‹åˆ†ä½ˆï¼š\n",
            "category\n",
            "å¢œè½ã€æ»¾è½       199\n",
            "ç‰©é«”å€’å¡Œã€å´©å¡Œ      36\n",
            "è¢«å¤¾ã€è¢«æ²        27\n",
            "ç‰©é«”é£›è½         24\n",
            "è·Œå€’           20\n",
            "è¢«æ’           13\n",
            "å…¶ä»–           10\n",
            "ç«ç½            8\n",
            "æ„Ÿé›»            8\n",
            "äº¤é€šäº‹æ•…          5\n",
            "è¡æ’            5\n",
            "çˆ†ç‚¸            4\n",
            "æººæ–ƒ            4\n",
            "èˆ‡æœ‰å®³ç‰©ç­‰ä¹‹æ¥è§¸      3\n",
            "èˆ‡é«˜æº«ã€ä½æº«æ¥è§¸      2\n",
            "è¢«åˆ‡ã€å‰²ã€æ“¦å‚·       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "æ­£åœ¨é€²è¡Œåˆ†å±¤åˆ‡åˆ†...\n",
            "è­¦å‘Šï¼šæŸäº›é¡åˆ¥æ¨£æœ¬å¤ªå°‘ï¼Œç„¡æ³•å®Œç¾åˆ†å±¤ã€‚è½‰ç‚ºéš¨æ©Ÿåˆ‡åˆ†ã€‚(éŒ¯èª¤: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.)\n",
            "è­¦å‘Šï¼šå‰©é¤˜è³‡æ–™é¡åˆ¥åˆ†ä½ˆç¨€ç–ï¼Œç¬¬äºŒéšæ®µè½‰ç‚ºéš¨æ©Ÿåˆ‡åˆ†ã€‚\n",
            "\n",
            "æª”æ¡ˆ: train.jsonl (300 ç­†)\n",
            "åˆ†ä½ˆæ¦‚æ³: {'å¢œè½ã€æ»¾è½': 162, 'ç‰©é«”å€’å¡Œã€å´©å¡Œ': 27, 'è¢«å¤¾ã€è¢«æ²': 26, 'ç‰©é«”é£›è½': 21, 'è·Œå€’': 14, 'è¢«æ’': 10, 'å…¶ä»–': 8, 'ç«ç½': 7, 'æ„Ÿé›»': 6, 'è¡æ’': 5, 'æººæ–ƒ': 4, 'äº¤é€šäº‹æ•…': 4, 'èˆ‡æœ‰å®³ç‰©ç­‰ä¹‹æ¥è§¸': 3, 'çˆ†ç‚¸': 2, 'èˆ‡é«˜æº«ã€ä½æº«æ¥è§¸': 1}\n",
            "\n",
            "æª”æ¡ˆ: val.jsonl (29 ç­†)\n",
            "åˆ†ä½ˆæ¦‚æ³: {'å¢œè½ã€æ»¾è½': 16, 'è·Œå€’': 4, 'ç‰©é«”å€’å¡Œã€å´©å¡Œ': 4, 'ç‰©é«”é£›è½': 2, 'çˆ†ç‚¸': 1, 'æ„Ÿé›»': 1, 'è¢«æ’': 1}\n",
            "\n",
            "æª”æ¡ˆ: test.jsonl (40 ç­†)\n",
            "åˆ†ä½ˆæ¦‚æ³: {'å¢œè½ã€æ»¾è½': 21, 'ç‰©é«”å€’å¡Œã€å´©å¡Œ': 5, 'è·Œå€’': 2, 'è¢«æ’': 2, 'å…¶ä»–': 2, 'è¢«å¤¾ã€è¢«æ²': 1, 'äº¤é€šäº‹æ•…': 1, 'ç‰©é«”é£›è½': 1, 'èˆ‡é«˜æº«ã€ä½æº«æ¥è§¸': 1, 'æ„Ÿé›»': 1, 'è¢«åˆ‡ã€å‰²ã€æ“¦å‚·': 1, 'çˆ†ç‚¸': 1, 'ç«ç½': 1}\n",
            "\n",
            "å…¨éƒ¨å®Œæˆï¼æª”æ¡ˆå·²å„²å­˜æ–¼ split_dataset_smart/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aKL8CP8bRAMT"
      }
    }
  ]
}